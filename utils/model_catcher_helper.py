"""
Helper para manejar cachÃ© de modelos ML
"""
import streamlit as st
from models.predictor import ImprovedStockPredictor
from data.processors.feature_engineering import FeatureEngineer


def load_data_for_ml_cached(ticker):
    """Wrapper para cargar datos con cachÃ©"""
    from data.collectors.market_data import MarketDataCollector
    
    collector = MarketDataCollector()
    data = collector.download_ticker(ticker, period='max')
    
    if data is not None:
        engineer = FeatureEngineer()
        data = engineer.add_technical_indicators(data)
    
    return data


def train_or_load_model(ticker, model_type='random_forest', test_size=0.2, 
                        use_cache=True, max_age_days=7, force_retrain=False):
    """
    Entrena un modelo nuevo o carga uno desde cachÃ©
    
    Args:
        ticker: SÃ­mbolo del ticker
        model_type: Tipo de modelo a usar
        test_size: ProporciÃ³n de datos para test
        use_cache: Si usar cachÃ©
        max_age_days: Edad mÃ¡xima del modelo en dÃ­as
        force_retrain: Forzar re-entrenamiento
        
    Returns:
        tuple: (predictor, data_clean, from_cache, metadata)
    """
    # Verificar cachÃ©
    cache_path = ImprovedStockPredictor.get_model_cache_path(
        ticker, 
        model_type=model_type,
        cache_dir='models/cache'
    )
    
    should_retrain = force_retrain
    metadata = None
    
    if use_cache and not force_retrain:
        is_valid, cache_metadata = ImprovedStockPredictor.check_cache_validity(
            cache_path, 
            max_age_days=max_age_days
        )
        
        if is_valid:
            # Intentar cargar desde cachÃ©
            try:
                st.info(f"""
                â™»ï¸ **Modelo encontrado en cachÃ©**  
                ðŸ“… Entrenado: {cache_metadata['trained_date'].strftime('%Y-%m-%d %H:%M')}  
                ðŸ“Š AntigÃ¼edad: {cache_metadata['age_days']} dÃ­a(s)  
                ðŸŽ¯ Modelos: {cache_metadata['n_models']}
                """)
                
                predictor = ImprovedStockPredictor(model_type=model_type)
                metadata = predictor.load_models(cache_path, verbose=False)
                
                # Cargar datos
                st.info("ðŸ“¥ Cargando datos actuales...")
                data_full = load_data_for_ml_cached(ticker)
                data_clean = data_full.dropna()
                
                st.success(f"âœ… Modelo cargado desde cachÃ© ({len(data_clean):,} muestras)")
                
                return predictor, data_clean, True, metadata
                
            except Exception as e:
                st.warning(f"âš ï¸ Error cargando cachÃ©: {e}. Entrenando nuevo modelo...")
                should_retrain = True
        else:
            if cache_metadata and cache_metadata.get('reason') == 'expired':
                st.warning(f"âš ï¸ Modelo expirado ({cache_metadata['age_days']} dÃ­as > {max_age_days}). Re-entrenando...")
            should_retrain = True
    
    # ENTRENAR NUEVO MODELO
    if should_retrain or not use_cache:
        st.info("ðŸ”„ Entrenando nuevo modelo desde cero...")
        
        # Cargar datos
        st.info("ðŸ“¥ Descargando histÃ³rico completo...")
        data_full = load_data_for_ml_cached(ticker)
        
        if data_full is None or len(data_full) < 50:
            raise ValueError(f"Datos insuficientes: {len(data_full) if data_full else 0} registros")
        
        data_clean = data_full.dropna()
        st.success(f"âœ… {len(data_clean):,} muestras listas para entrenamiento")
        
        # Entrenar
        predictor = ImprovedStockPredictor(model_type=model_type)
        
        with st.spinner('ðŸ§  Entrenando modelos multi-horizonte...'):
            trained_count = predictor.train_all_horizons(
                data_clean, 
                test_size=test_size
            )
        
        st.success(f"âœ… {trained_count} modelos entrenados")
        
        # Guardar en cachÃ©
        if use_cache:
            predictor.save_models(
                filepath=cache_path,
                ticker=ticker,
                data_hash=None
            )
            st.success(f"ðŸ’¾ Guardado en cachÃ©: {cache_path}")
        
        return predictor, data_clean, False, None